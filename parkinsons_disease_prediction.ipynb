{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMeWJU8YyRvvOTwBUYwj/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitunalam/idp-parikinsons-disease-detection/blob/main/parkinsons_disease_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6_s-kxxQQyi"
      },
      "outputs": [],
      "source": [
        "!pip install -q keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "A0L327TlQXTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "RzLiWcYJQZof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.layers import Input, Lambda, Dense, Flatten,GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "60eyFpNKQcn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow keras\n"
      ],
      "metadata": {
        "id": "b-evTyH3QhhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the data generators with appropriate parameters\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data from the directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/parkinson/Dataset/train',\n",
        "        batch_size=1,\n",
        "        target_size=(100, 100),\n",
        "        class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load the testing data from the directory\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/parkinson/Dataset/test',\n",
        "        batch_size=1,\n",
        "        target_size=(100, 100),\n",
        "        class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load the validation data from the directory\n",
        "val_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/parkinson/Dataset/valid',\n",
        "        batch_size=1,\n",
        "        target_size=(100, 100),\n",
        "        class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "6Si9p8LKQj5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "image = cv2.imread(\"/content/drive/MyDrive/parkinson/Dataset/test/images/NoneDem-9-_jpg.rf.5da58cb6258651e1a070922dee8ad9df.jpg\")\n",
        "plt.imshow(image)\n",
        "image.shape\n"
      ],
      "metadata": {
        "id": "HnXkXT2iQxWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "image = cv2.imread(\"/content/drive/MyDrive/parkinson/Dataset/train/images/MildDem-1-_jpg.rf.6bdba105abc128164d6109c86861cfa1.jpg\")\n",
        "plt.imshow(image)\n",
        "image.shape\n"
      ],
      "metadata": {
        "id": "4JIYX4XFQ0G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Build the base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "base_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "nTTOW4OfQ4V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "\n",
        "# Add custom layers for classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)  # You can adjust the number of neurons\n",
        "predictions = Dense(2, activation='softmax')(x)  # Assuming binary classification\n",
        "\n",
        "# Create the model\n",
        "from tensorflow.keras.models import Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "FTQ48MWQQ7Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "base_model = VGG16(weights='imagenet', input_shape=(224, 224, 3))\n",
        "model = Model(inputs = base_model.input, outputs = base_model.get_layer(\"fc1\").output)\n",
        "\n"
      ],
      "metadata": {
        "id": "5FWg-beIQ-bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Import load_img and img_to_array\n",
        "\n",
        "# Define the training directory path\n",
        "train_dir = '/content/drive/MyDrive/parkinson/Dataset/train'\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(train_dir, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(train_dir))\n",
        "    label_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(train_dir, class_name)\n",
        "        for img_path in os.listdir(class_dir):\n",
        "            img = load_img(os.path.join(class_dir, img_path), target_size=(224, 224))  # Adjust size as needed\n",
        "            img_array = img_to_array(img)  # Convert image to array\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            feature = model.predict(img_array)\n",
        "            features.append(feature)\n",
        "            labels.append(label_dict[class_name])\n",
        "    return np.vstack(features), np.array(labels)\n",
        "train_dir = '/content/drive/MyDrive/parkinson/Dataset/train'  # Ensure this is a valid directory with image files\n",
        "features, labels = extract_features(train_dir, base_model)\n",
        "# Extract features and labels\n",
        "#features, labels = extract_features(train_dir, model)\n",
        "\n",
        "# Flatten the features if needed\n",
        "def flatten_features(features):\n",
        "    return features.reshape(features.shape[0], -1)\n",
        "\n",
        "\n",
        "\n",
        "features = flatten_features(features)\n",
        "print(\"Feature vector dimensions: \",features.shape)\n"
      ],
      "metadata": {
        "id": "bVnvpslDRHjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "dataset_dir = '/content/drive/MyDrive/parkinson/Dataset'\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224  # Image size compatible with VGG16\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Feature Extraction using VGG16\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Extract features and flatten them\n",
        "def extract_features(generator, model, batch_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = model.predict(inputs_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(labels_batch)\n",
        "        if len(features) * batch_size >= generator.samples:\n",
        "            break\n",
        "    features = np.vstack(features)\n",
        "    labels = np.hstack(labels)\n",
        "    return features, labels\n",
        "\n",
        "# Extract features for training and validation data\n",
        "train_features, train_labels = extract_features(train_generator, vgg16_model, batch_size)\n",
        "validation_features, validation_labels = extract_features(validation_generator, vgg16_model, batch_size)\n",
        "\n",
        "# Reshape the features to fit classifiers (flattening)\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "validation_features = validation_features.reshape(validation_features.shape[0], -1)\n",
        "\n",
        "# Split training data for train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm_clf = SVC(kernel='linear', C=1)  # You can experiment with different kernels\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate SVM\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_cm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_cm)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_cm = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%\")\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(dt_cm)\n",
        "\n",
        "# Train KNN Classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate KNN\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"KNN Accuracy: {knn_accuracy * 100:.2f}%\")\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(knn_cm)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0E4w-pwQRZNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train ANN Classifier\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann_model.add(Dropout(0.5))\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the ANN\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict and evaluate ANN\n",
        "y_pred_ann = (ann_model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary\n",
        "ann_accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "ann_cm = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "print(f\"ANN Accuracy: {ann_accuracy * 100:.2f}%\")\n",
        "print(\"ANN Confusion Matrix:\")\n",
        "print(ann_cm)\n",
        "# ANN Confusion Matrix\n",
        "sns.heatmap(cm_ann, annot=True, fmt='d', cmap='Purples', ax=axes[1, 1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1, 1].set_title('ANN Confusion Matrix', fontsize=16)\n",
        "axes[1, 1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1, 1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "69ETm1xIR3Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Assuming you already have X_train, X_test, y_train, and y_test defined\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm_clf = SVC(kernel='linear', C=1)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate SVM\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "y_pred_tree = decision_tree.predict(X_test)\n",
        "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
        "\n",
        "# Train KNN Classifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate KNN\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "# Train ANN Classifier\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Predictions and evaluation for ANN\n",
        "y_pred_ann = ann_model.predict(X_test)\n",
        "y_pred_ann = (y_pred_ann > 0.5).astype(int)  # Convert probabilities to binary\n",
        "cm_ann = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "# Plotting the confusion matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "# SVM Confusion Matrix\n",
        "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Purples', ax=axes[0, 0],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[0, 0].set_title('SVM Confusion Matrix', fontsize=16)\n",
        "axes[0, 0].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[0, 0].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# Decision Tree Confusion Matrix\n",
        "sns.heatmap(cm_tree, annot=True, fmt='d', cmap='Purples', ax=axes[0, 1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[0, 1].set_title('Decision Tree Confusion Matrix', fontsize=16)\n",
        "axes[0, 1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[0, 1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# KNN Confusion Matrix\n",
        "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Purples', ax=axes[1, 0],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1, 0].set_title('KNN Confusion Matrix', fontsize=16)\n",
        "axes[1, 0].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1, 0].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# ANN Confusion Matrix\n",
        "sns.heatmap(cm_ann, annot=True, fmt='d', cmap='Purples', ax=axes[1, 1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1, 1].set_title('ANN Confusion Matrix', fontsize=16)\n",
        "axes[1, 1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1, 1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zts1x_Q6R8p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Sample accuracy values\n",
        "accuracies = {\n",
        "    'SVM': 93.19,\n",
        "    'Decision Tree': 92.86,\n",
        "    'KNN': 96.51,\n",
        "    'ANN': 94.19\n",
        "}\n",
        "\n",
        "# Sample confusion matrices\n",
        "confusion_matrices = {\n",
        "    'SVM': np.array([[0, 1, 0],\n",
        "                     [0, 555, 25],\n",
        "                     [0, 15, 6]]),\n",
        "    'Decision Tree': np.array([[0, 1, 0],\n",
        "                                [0, 555, 25],\n",
        "                                [1, 16, 4]]),\n",
        "    'KNN': np.array([[0, 1, 0],\n",
        "                     [0, 578, 2],\n",
        "                     [0, 18, 3]]),\n",
        "    'ANN': np.array([[0, 1, 0],\n",
        "                     [0, 567, 0],\n",
        "                     [0, 34, 0]])\n",
        "}\n",
        "\n",
        "# Plotting Confusion Matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (clf_name, cm) in enumerate(confusion_matrices.items()):\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                cbar=True, xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
        "    axes[i].set_title(f'{clf_name} Confusion Matrix', fontsize=16)\n",
        "    axes[i].set_xlabel('Predicted', fontsize=12)\n",
        "    axes[i].set_ylabel('True', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting Accuracy Comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(accuracies.keys(), accuracies.values(), color=['purple', 'orange', 'green', 'blue'])\n",
        "\n",
        "# Adding accuracy values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, f\"{yval:.2f}%\", va='bottom', ha='center')  # va: vertical alignment\n",
        "\n",
        "plt.title('Classifier Accuracy Comparison', fontsize=16)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.ylim(90, 100)  # Set the y-axis limit from 90 to 100 for better visualization\n",
        "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9vlqAywHSFbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "dataset_dir = '/content/drive/MyDrive/parkinson/Dataset'\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224  # Image size compatible with VGG16\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Feature Extraction using VGG19\n",
        "vgg19_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Extract features and flatten them\n",
        "def extract_features(generator, model, batch_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = model.predict(inputs_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(labels_batch)\n",
        "        if len(features) * batch_size >= generator.samples:\n",
        "            break\n",
        "    features = np.vstack(features)\n",
        "    labels = np.hstack(labels)\n",
        "    return features, labels\n",
        "\n",
        "# Extract features for training and validation data\n",
        "train_features, train_labels = extract_features(train_generator, vgg19_model, batch_size)\n",
        "validation_features, validation_labels = extract_features(validation_generator, vgg19_model, batch_size)\n",
        "\n",
        "# Reshape the features to fit classifiers (flattening)\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "validation_features = validation_features.reshape(validation_features.shape[0], -1)\n",
        "\n",
        "# Split training data for train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm_clf = SVC(kernel='linear', C=1)  # You can experiment with different kernels\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate SVM\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_cm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_cm)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_cm = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%\")\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(dt_cm)\n",
        "\n",
        "# Train KNN Classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate KNN\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"KNN Accuracy: {knn_accuracy * 100:.2f}%\")\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(knn_cm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XFil00FOSJnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train ANN Classifier\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann_model.add(Dropout(0.5))\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the ANN\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict and evaluate ANN\n",
        "y_pred_ann = (ann_model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary\n",
        "ann_accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "ann_cm = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "print(f\"ANN Accuracy: {ann_accuracy * 100:.2f}%\")\n",
        "print(\"ANN Confusion Matrix:\")\n",
        "print(ann_cm)\n",
        "# ANN Confusion Matrix\n",
        "sns.heatmap(cm_ann, annot=True, fmt='d', cmap='Purples', ax=axes[1, 1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1, 1].set_title('ANN Confusion Matrix', fontsize=16)\n",
        "axes[1, 1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1, 1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eSNL3OdNSRAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Updated accuracy values\n",
        "accuracies = {\n",
        "    'SVM': 94.85,\n",
        "    'Decision Tree': 92.36,\n",
        "    'KNN': 96.35,\n",
        "    'ANN': 94.19\n",
        "}\n",
        "\n",
        "# Updated confusion matrices\n",
        "confusion_matrices = {\n",
        "    'SVM': np.array([[0, 2, 0],\n",
        "                     [0, 564, 12],\n",
        "                     [0, 17, 7]]),\n",
        "    'Decision Tree': np.array([[0, 2, 0],\n",
        "                               [0, 552, 24],\n",
        "                               [0, 20, 4]]),\n",
        "    'KNN': np.array([[0, 2, 0],\n",
        "                     [0, 576, 0],\n",
        "                     [0, 20, 4]]),\n",
        "    'ANN': np.array([[0, 1, 0],\n",
        "                     [0, 567, 0],\n",
        "                     [0, 34, 0]])\n",
        "}\n",
        "\n",
        "# Plotting Confusion Matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (clf_name, cm) in enumerate(confusion_matrices.items()):\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                cbar=True, xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
        "    axes[i].set_title(f'{clf_name} Confusion Matrix', fontsize=16)\n",
        "    axes[i].set_xlabel('Predicted', fontsize=12)\n",
        "    axes[i].set_ylabel('True', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting Accuracy Comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(accuracies.keys(), accuracies.values(), color=['purple', 'orange', 'green', 'blue'])\n",
        "\n",
        "# Adding accuracy values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, f\"{yval:.2f}%\", va='bottom', ha='center')  # va: vertical alignment\n",
        "\n",
        "plt.title('Classifier Accuracy Comparison', fontsize=16)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.ylim(90, 100)  # Set the y-axis limit from 90 to 100 for better visualization\n",
        "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')  # Add threshold line at 95%\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SW1CVlwJSVhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "dataset_dir = '/content/drive/MyDrive/parkinson/Dataset'\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224  # Image size compatible with ResNet50\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Feature Extraction using ResNet50\n",
        "resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Extract features and flatten them\n",
        "def extract_features(generator, model, batch_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = model.predict(inputs_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(labels_batch)\n",
        "        if len(features) * batch_size >= generator.samples:\n",
        "            break\n",
        "    features = np.vstack(features)\n",
        "    labels = np.hstack(labels)\n",
        "    return features, labels\n",
        "\n",
        "# Extract features for training and validation data\n",
        "train_features, train_labels = extract_features(train_generator, resnet50_model, batch_size)\n",
        "validation_features, validation_labels = extract_features(validation_generator, resnet50_model, batch_size)\n",
        "\n",
        "# Reshape the features to fit classifiers (flattening)\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "validation_features = validation_features.reshape(validation_features.shape[0], -1)\n",
        "\n",
        "# Split training data for train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm_clf = SVC(kernel='linear', C=1)  # You can experiment with different kernels\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate SVM\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_cm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_cm)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_cm = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%\")\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(dt_cm)\n",
        "\n",
        "# Train KNN Classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate KNN\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"KNN Accuracy: {knn_accuracy * 100:.2f}%\")\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(knn_cm)\n",
        "\n",
        "# Build and Train ANN Classifier\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann_model.add(Dropout(0.5))\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the ANN\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict and evaluate ANN\n",
        "y_pred_ann = (ann_model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary\n",
        "ann_accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "ann_cm = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "print(f\"ANN Accuracy: {ann_accuracy * 100:.2f}%\")\n",
        "print(\"ANN Confusion Matrix:\")\n",
        "print(ann_cm)\n",
        "\n",
        "# Plotting all confusion matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# SVM Confusion Matrix\n",
        "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[0].set_title('SVM Confusion Matrix', fontsize=16)\n",
        "axes[0].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[0].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# Decision Tree Confusion Matrix\n",
        "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1].set_title('Decision Tree Confusion Matrix', fontsize=16)\n",
        "axes[1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# KNN Confusion Matrix\n",
        "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Greens', ax=axes[2],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[2].set_title('KNN Confusion Matrix', fontsize=16)\n",
        "axes[2].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[2].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# ANN Confusion Matrix (Fixed the variable name)\n",
        "sns.heatmap(ann_cm, annot=True, fmt='d', cmap='Purples', ax=axes[3],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[3].set_title('ANN Confusion Matrix', fontsize=16)\n",
        "axes[3].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[3].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MOCohCAPScVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "dataset_dir = '/content/drive/MyDrive/parkinson/Dataset'\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224  # Image size compatible with ResNet50\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Feature Extraction using ResNet50\n",
        "resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Extract features and flatten them\n",
        "def extract_features(generator, model, batch_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = model.predict(inputs_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(labels_batch)\n",
        "        if len(features) * batch_size >= generator.samples:\n",
        "            break\n",
        "    features = np.vstack(features)\n",
        "    labels = np.hstack(labels)\n",
        "    return features, labels\n",
        "\n",
        "# Extract features for training and validation data\n",
        "train_features, train_labels = extract_features(train_generator, resnet50_model, batch_size)\n",
        "validation_features, validation_labels = extract_features(validation_generator, resnet50_model, batch_size)\n",
        "\n",
        "# Reshape the features to fit classifiers (flattening)\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "validation_features = validation_features.reshape(validation_features.shape[0], -1)\n",
        "\n",
        "# Split training data for train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm_clf = SVC(kernel='linear', C=1)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate SVM\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_cm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_cm)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_cm = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%\")\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(dt_cm)\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# Train KNN Classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate KNN\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"KNN Accuracy: {knn_accuracy * 100:.2f}%\")\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(knn_cm)\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Build and Train ANN Classifier\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann_model.add(Dropout(0.5))\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the ANN\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict and evaluate ANN\n",
        "y_pred_ann = (ann_model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary\n",
        "ann_accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "ann_cm = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "print(f\"ANN Accuracy: {ann_accuracy * 100:.2f}%\")\n",
        "print(\"ANN Confusion Matrix:\")\n",
        "print(ann_cm)\n",
        "print(classification_report(y_test, y_pred_ann))\n",
        "\n",
        "# Plotting all confusion matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# SVM Confusion Matrix\n",
        "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[0].set_title('SVM Confusion Matrix', fontsize=16)\n",
        "axes[0].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[0].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# Decision Tree Confusion Matrix\n",
        "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1].set_title('Decision Tree Confusion Matrix', fontsize=16)\n",
        "axes[1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# KNN Confusion Matrix\n",
        "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Greens', ax=axes[2],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[2].set_title('KNN Confusion Matrix', fontsize=16)\n",
        "axes[2].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[2].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "# ANN Confusion Matrix\n",
        "sns.heatmap(ann_cm, annot=True, fmt='d', cmap='Purples', ax=axes[3],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[3].set_title('ANN Confusion Matrix', fontsize=16)\n",
        "axes[3].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[3].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mh27MoqISoNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Updated accuracy values\n",
        "accuracies = {\n",
        "    'SVM': 94.35,\n",
        "    'Decision Tree': 93.19,\n",
        "    'KNN': 96.68,\n",
        "    'ANN': 96.35\n",
        "}\n",
        "\n",
        "# Updated confusion matrices\n",
        "confusion_matrices = {\n",
        "    'SVM': np.array([[0, 1, 0],\n",
        "                     [0, 562, 18],\n",
        "                     [0, 15, 6]]),\n",
        "    'Decision Tree': np.array([[0, 1, 0],\n",
        "                               [0, 554, 26],\n",
        "                               [0, 14, 7]]),\n",
        "    'KNN': np.array([[0, 1, 0],\n",
        "                     [0, 578, 2],\n",
        "                     [0, 17, 4]]),\n",
        "    'ANN': np.array([[0, 1, 0],\n",
        "                     [0, 580, 0],\n",
        "                     [0, 21, 0]])\n",
        "}\n",
        "\n",
        "# Plotting Confusion Matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (clf_name, cm) in enumerate(confusion_matrices.items()):\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                cbar=True, xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
        "    axes[i].set_title(f'{clf_name} Confusion Matrix', fontsize=16)\n",
        "    axes[i].set_xlabel('Predicted', fontsize=12)\n",
        "    axes[i].set_ylabel('True', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting Accuracy Comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(accuracies.keys(), accuracies.values(), color=['purple', 'orange', 'green', 'blue'])\n",
        "\n",
        "# Adding accuracy values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, f\"{yval:.2f}%\", va='bottom', ha='center')\n",
        "\n",
        "plt.title('Classifier Accuracy Comparison', fontsize=16)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.ylim(90, 100)  # Set the y-axis limit from 90 to 100 for better visualization\n",
        "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')  # Add threshold line at 95%\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2_Sc3XOVSyOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "dataset_dir = '/content/drive/MyDrive/parkinson/Dataset'\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224  # Image size compatible with VGG16\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Feature Extraction using VGG19\n",
        "vgg19_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Extract features and flatten them\n",
        "def extract_features(generator, model, batch_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = model.predict(inputs_batch)\n",
        "        features.append(features_batch)\n",
        "        labels.append(labels_batch)\n",
        "        if len(features) * batch_size >= generator.samples:\n",
        "            break\n",
        "    features = np.vstack(features)\n",
        "    labels = np.hstack(labels)\n",
        "    return features, labels\n",
        "\n",
        "# Extract features for training and validation data\n",
        "train_features, train_labels = extract_features(train_generator, vgg19_model, batch_size)\n",
        "validation_features, validation_labels = extract_features(validation_generator, vgg19_model, batch_size)\n",
        "\n",
        "# Reshape the features to fit classifiers (flattening)\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "validation_features = validation_features.reshape(validation_features.shape[0], -1)\n",
        "\n",
        "# Split training data for train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm_clf = SVC(kernel='linear', C=1)  # You can experiment with different kernels\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate SVM\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_cm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_cm)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Decision Tree\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_cm = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%\")\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(dt_cm)\n",
        "\n",
        "# Train KNN Classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate KNN\n",
        "y_pred_knn = knn_clf.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"KNN Accuracy: {knn_accuracy * 100:.2f}%\")\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(knn_cm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jtE97Ys5SzMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train ANN Classifier\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann_model.add(Dropout(0.5))\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the ANN\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict and evaluate ANN\n",
        "y_pred_ann = (ann_model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary\n",
        "ann_accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "ann_cm = confusion_matrix(y_test, y_pred_ann)\n",
        "\n",
        "print(f\"ANN Accuracy: {ann_accuracy * 100:.2f}%\")\n",
        "print(\"ANN Confusion Matrix:\")\n",
        "print(ann_cm)\n",
        "# ANN Confusion Matrix\n",
        "sns.heatmap(cm_ann, annot=True, fmt='d', cmap='Purples', ax=axes[1, 1],\n",
        "            cbar=True, xticklabels=['0', '1'], yticklabels=['0', '1'], linewidths=0.5)\n",
        "axes[1, 1].set_title('ANN Confusion Matrix', fontsize=16)\n",
        "axes[1, 1].set_xlabel('Predicted Label', fontsize=14)\n",
        "axes[1, 1].set_ylabel('True Label', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jKwLnbe4S4zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Updated accuracy values\n",
        "accuracies = {\n",
        "    'SVM': 94.85,\n",
        "    'Decision Tree': 92.36,\n",
        "    'KNN': 96.35,\n",
        "    'ANN': 94.19\n",
        "}\n",
        "\n",
        "# Updated confusion matrices\n",
        "confusion_matrices = {\n",
        "    'SVM': np.array([[0, 2, 0],\n",
        "                     [0, 564, 12],\n",
        "                     [0, 17, 7]]),\n",
        "    'Decision Tree': np.array([[0, 2, 0],\n",
        "                               [0, 552, 24],\n",
        "                               [0, 20, 4]]),\n",
        "    'KNN': np.array([[0, 2, 0],\n",
        "                     [0, 576, 0],\n",
        "                     [0, 20, 4]]),\n",
        "    'ANN': np.array([[0, 1, 0],\n",
        "                     [0, 567, 0],\n",
        "                     [0, 34, 0]])\n",
        "}\n",
        "\n",
        "# Plotting Confusion Matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (clf_name, cm) in enumerate(confusion_matrices.items()):\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                cbar=True, xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
        "    axes[i].set_title(f'{clf_name} Confusion Matrix', fontsize=16)\n",
        "    axes[i].set_xlabel('Predicted', fontsize=12)\n",
        "    axes[i].set_ylabel('True', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting Accuracy Comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(accuracies.keys(), accuracies.values(), color=['purple', 'orange', 'green', 'blue'])\n",
        "\n",
        "# Adding accuracy values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, f\"{yval:.2f}%\", va='bottom', ha='center')  # va: vertical alignment\n",
        "\n",
        "plt.title('Classifier Accuracy Comparison', fontsize=16)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.ylim(90, 100)  # Set the y-axis limit from 90 to 100 for better visualization\n",
        "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')  # Add threshold line at 95%\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Hpznx1AAS8Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ap2Hj7QaTAdf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}